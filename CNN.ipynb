{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEPS INVOLVED:**\n",
    "1. Import the libraries\n",
    "2. Image Processing and Data Augmentation\n",
    "3. Initialize the model\n",
    "4. Add Convolution Layer _(image size, how many feature detectors, size of featire detectors)_\n",
    "5. Add Pooling Layer\n",
    "6. Add Flatten Layer\n",
    "7. Add I/P layer\n",
    "8. Add Hidden Layers\n",
    "9. Add O/P Layer\n",
    "10. Compile the process\n",
    "11. Train the data\n",
    "12. Save the model\n",
    "13. Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HOW TO MAKE A DATASET?**\n",
    "1. ***Make a main folder for categorical o/p***\n",
    "\n",
    "> Inside it, _Test Folder_ : chairs (30 images), pens (30), fans (30), tables(30)\n",
    "\n",
    "> _Train Folder_ : chairs (70), pens (70), fans (70), tables (70)\n",
    "\n",
    "2. ***Make a main folder for classification o/p***\n",
    "\n",
    "> _Test Set_: healthy (30), non-healthy (30)\n",
    "\n",
    "> _Train set_: healthy (70), non-healthy (70)\n",
    "\n",
    "3. ___Higher the images, higher the accuracy___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Convolution2D, MaxPooling2D, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image Preprocessing\n",
    "> **Augmenting** the images by applying some more featires and rescaling it.\n",
    "\n",
    "> ___Augmentation:___ In order to make the training more accurate, train the images from different angles. **Rescaling** the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# rescale - scaling the images into a single range\n",
    "# Here, the image is getting zoomed and flipped\n",
    "# shear_range - the image can be stretched either in the s or y direction (stretched images)\n",
    "\n",
    "train_datagen = ImageDataGenerator (rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator (rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1495 images belonging to 5 classes.\n",
      "Found 640 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Since all the images are of different sizes, we make them of similar sizes using target_size\n",
    "# batch size indicates the number of images whihc will be trained in a batch\n",
    "\n",
    "x_train = train_datagen.flow_from_directory(r'C:\\Users\\anann\\OneDrive\\Desktop\\College\\AI_SmartBridge\\CNN\\Crop-animal data\\trainset', target_size = (64,64),batch_size = 32,class_mode = \"categorical\"\n",
    ")\n",
    "x_test = test_datagen.flow_from_directory(r'C:\\Users\\anann\\OneDrive\\Desktop\\College\\AI_SmartBridge\\CNN\\Crop-animal data\\testset', target_size = (64,64),batch_size = 32,class_mode = \"categorical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bears': 0, 'crows': 1, 'elephants': 2, 'racoons': 3, 'rats': 4}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Add Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no of feature detectors = 32\n",
    "# size of feature detectors = (3,3)\n",
    "# image size = 64, 64\n",
    "# 3 indicates RGB (3 channels) for colored images\n",
    "\n",
    "model.add(Convolution2D(32, (3,3), input_shape = (64,64,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Add Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add pool size, the conventional size is 2 by 2\n",
    "\n",
    "model.add(MaxPooling2D ((2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add another convolution layer\n",
    "model.add(Convolution2D(32, (3,3), input_shape = (64,64,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding another max pool for the above convolution layer\n",
    "model.add(MaxPooling2D ((2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Add Flatten/Input Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Add Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units = 128, kernel_initializer = \"random_uniform\", activation =\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly turn neurons on and off to improve convergence\n",
    "# Add dropout layer\n",
    "model.add(Dropout(0.3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units = 128, kernel_initializer = \"random_uniform\", activation =\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add another Dropout layer\n",
    "model.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units = 128, kernel_initializer = \"random_uniform\", activation =\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Add Ouput Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units = 5, kernel_initializer = \"random_uniform\", activation =\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Compile the Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> steps per epoch is the number of images the model is trained on -> **number of images in train set / batch size** = 1495/32\n",
    "\n",
    "> validation steps is the no of images the model tests upon -> no of **images in test set / batch size** = 640/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Train the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anann\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "47/47 [==============================] - 9s 184ms/step - loss: 1.5942 - accuracy: 0.2468 - val_loss: 1.4748 - val_accuracy: 0.5781\n",
      "Epoch 2/50\n",
      "47/47 [==============================] - 10s 221ms/step - loss: 1.4900 - accuracy: 0.3130 - val_loss: 1.1827 - val_accuracy: 0.6203\n",
      "Epoch 3/50\n",
      "47/47 [==============================] - 11s 238ms/step - loss: 1.3380 - accuracy: 0.4609 - val_loss: 0.9602 - val_accuracy: 0.6469\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 10s 210ms/step - loss: 1.1747 - accuracy: 0.5331 - val_loss: 1.0162 - val_accuracy: 0.6156\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 10s 212ms/step - loss: 1.1012 - accuracy: 0.5672 - val_loss: 0.9857 - val_accuracy: 0.5906\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 10s 225ms/step - loss: 0.9997 - accuracy: 0.6040 - val_loss: 0.8877 - val_accuracy: 0.6391\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 11s 233ms/step - loss: 0.9414 - accuracy: 0.6428 - val_loss: 0.7408 - val_accuracy: 0.7156\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 10s 220ms/step - loss: 0.8675 - accuracy: 0.6709 - val_loss: 0.8522 - val_accuracy: 0.6422\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 11s 235ms/step - loss: 0.7901 - accuracy: 0.7017 - val_loss: 0.7259 - val_accuracy: 0.7094\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 11s 225ms/step - loss: 0.7217 - accuracy: 0.7291 - val_loss: 0.5732 - val_accuracy: 0.7797\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 11s 234ms/step - loss: 0.6885 - accuracy: 0.7498 - val_loss: 0.6128 - val_accuracy: 0.7688\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 11s 235ms/step - loss: 0.6606 - accuracy: 0.7773 - val_loss: 0.4865 - val_accuracy: 0.7984\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 12s 259ms/step - loss: 0.5833 - accuracy: 0.7967 - val_loss: 0.3598 - val_accuracy: 0.8578\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 13s 283ms/step - loss: 0.5470 - accuracy: 0.8127 - val_loss: 0.3619 - val_accuracy: 0.8656\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 11s 231ms/step - loss: 0.4948 - accuracy: 0.8201 - val_loss: 0.3624 - val_accuracy: 0.8422\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 10s 221ms/step - loss: 0.4616 - accuracy: 0.8408 - val_loss: 0.2283 - val_accuracy: 0.9266\n",
      "Epoch 17/50\n",
      "47/47 [==============================] - 11s 235ms/step - loss: 0.4345 - accuracy: 0.8502 - val_loss: 0.2867 - val_accuracy: 0.8891\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 11s 229ms/step - loss: 0.4899 - accuracy: 0.8241 - val_loss: 0.2888 - val_accuracy: 0.8938\n",
      "Epoch 19/50\n",
      "47/47 [==============================] - 11s 235ms/step - loss: 0.3732 - accuracy: 0.8722 - val_loss: 0.1801 - val_accuracy: 0.9312\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 13s 269ms/step - loss: 0.3517 - accuracy: 0.8829 - val_loss: 0.1198 - val_accuracy: 0.9547\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 11s 228ms/step - loss: 0.3488 - accuracy: 0.8923 - val_loss: 0.1486 - val_accuracy: 0.9563\n",
      "Epoch 22/50\n",
      "47/47 [==============================] - 10s 220ms/step - loss: 0.2779 - accuracy: 0.9043 - val_loss: 0.0961 - val_accuracy: 0.9656\n",
      "Epoch 23/50\n",
      "47/47 [==============================] - 11s 236ms/step - loss: 0.2707 - accuracy: 0.9050 - val_loss: 0.1021 - val_accuracy: 0.9672\n",
      "Epoch 24/50\n",
      "47/47 [==============================] - 11s 235ms/step - loss: 0.2793 - accuracy: 0.9077 - val_loss: 0.0873 - val_accuracy: 0.9688\n",
      "Epoch 25/50\n",
      "47/47 [==============================] - 11s 245ms/step - loss: 0.3246 - accuracy: 0.8890 - val_loss: 0.1924 - val_accuracy: 0.9219\n",
      "Epoch 26/50\n",
      "47/47 [==============================] - 10s 220ms/step - loss: 0.2591 - accuracy: 0.9090 - val_loss: 0.0787 - val_accuracy: 0.9734\n",
      "Epoch 27/50\n",
      "47/47 [==============================] - 10s 220ms/step - loss: 0.2559 - accuracy: 0.9244 - val_loss: 0.0570 - val_accuracy: 0.9891\n",
      "Epoch 28/50\n",
      "47/47 [==============================] - 10s 222ms/step - loss: 0.2250 - accuracy: 0.9271 - val_loss: 0.1146 - val_accuracy: 0.9563\n",
      "Epoch 29/50\n",
      "47/47 [==============================] - 10s 217ms/step - loss: 0.2042 - accuracy: 0.9284 - val_loss: 0.0779 - val_accuracy: 0.9750\n",
      "Epoch 30/50\n",
      "47/47 [==============================] - 10s 218ms/step - loss: 0.2059 - accuracy: 0.9284 - val_loss: 0.0504 - val_accuracy: 0.9781\n",
      "Epoch 31/50\n",
      "47/47 [==============================] - 11s 240ms/step - loss: 0.2017 - accuracy: 0.9358 - val_loss: 0.0508 - val_accuracy: 0.9875\n",
      "Epoch 32/50\n",
      "47/47 [==============================] - 12s 247ms/step - loss: 0.1772 - accuracy: 0.9405 - val_loss: 0.0760 - val_accuracy: 0.9609\n",
      "Epoch 33/50\n",
      "47/47 [==============================] - 11s 231ms/step - loss: 0.2457 - accuracy: 0.9258 - val_loss: 0.0672 - val_accuracy: 0.9812\n",
      "Epoch 34/50\n",
      "47/47 [==============================] - 11s 234ms/step - loss: 0.2068 - accuracy: 0.9338 - val_loss: 0.0425 - val_accuracy: 0.9891\n",
      "Epoch 35/50\n",
      "47/47 [==============================] - 11s 225ms/step - loss: 0.2288 - accuracy: 0.9231 - val_loss: 0.0685 - val_accuracy: 0.9703\n",
      "Epoch 36/50\n",
      "47/47 [==============================] - 11s 234ms/step - loss: 0.1970 - accuracy: 0.9338 - val_loss: 0.0373 - val_accuracy: 0.9859\n",
      "Epoch 37/50\n",
      "47/47 [==============================] - 12s 251ms/step - loss: 0.1917 - accuracy: 0.9391 - val_loss: 0.0645 - val_accuracy: 0.9859\n",
      "Epoch 38/50\n",
      "47/47 [==============================] - 11s 226ms/step - loss: 0.1701 - accuracy: 0.9478 - val_loss: 0.0195 - val_accuracy: 0.9969\n",
      "Epoch 39/50\n",
      "47/47 [==============================] - 11s 236ms/step - loss: 0.1847 - accuracy: 0.9358 - val_loss: 0.0286 - val_accuracy: 0.9922\n",
      "Epoch 40/50\n",
      "47/47 [==============================] - 11s 242ms/step - loss: 0.1464 - accuracy: 0.9512 - val_loss: 0.0190 - val_accuracy: 0.9984\n",
      "Epoch 41/50\n",
      "47/47 [==============================] - 11s 227ms/step - loss: 0.1346 - accuracy: 0.9585 - val_loss: 0.0449 - val_accuracy: 0.9797\n",
      "Epoch 42/50\n",
      "47/47 [==============================] - 11s 240ms/step - loss: 0.1325 - accuracy: 0.9532 - val_loss: 0.0242 - val_accuracy: 0.9906\n",
      "Epoch 43/50\n",
      "47/47 [==============================] - 11s 226ms/step - loss: 0.1145 - accuracy: 0.9692 - val_loss: 0.0176 - val_accuracy: 0.9937\n",
      "Epoch 44/50\n",
      "47/47 [==============================] - 11s 228ms/step - loss: 0.1378 - accuracy: 0.9585 - val_loss: 0.0462 - val_accuracy: 0.9891\n",
      "Epoch 45/50\n",
      "47/47 [==============================] - 11s 234ms/step - loss: 0.1485 - accuracy: 0.9498 - val_loss: 0.0118 - val_accuracy: 0.9953\n",
      "Epoch 46/50\n",
      "47/47 [==============================] - 11s 238ms/step - loss: 0.1143 - accuracy: 0.9672 - val_loss: 0.0074 - val_accuracy: 0.9984\n",
      "Epoch 47/50\n",
      "47/47 [==============================] - 11s 238ms/step - loss: 0.1272 - accuracy: 0.9639 - val_loss: 0.0137 - val_accuracy: 0.9937\n",
      "Epoch 48/50\n",
      "47/47 [==============================] - 13s 276ms/step - loss: 0.1097 - accuracy: 0.9599 - val_loss: 0.0065 - val_accuracy: 0.9984\n",
      "Epoch 49/50\n",
      "47/47 [==============================] - 11s 227ms/step - loss: 0.1341 - accuracy: 0.9472 - val_loss: 0.0149 - val_accuracy: 0.9937\n",
      "Epoch 50/50\n",
      "47/47 [==============================] - 11s 224ms/step - loss: 0.1024 - accuracy: 0.9612 - val_loss: 0.0180 - val_accuracy: 0.9953\n"
     ]
    }
   ],
   "source": [
    " \n",
    "hist = model.fit_generator(x_train,steps_per_epoch = 47 , epochs = 50 , validation_data = x_test, validation_steps = 20, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26257de21c0>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot loss\n",
    "plt.subplot(3,1,1)\n",
    "plt.title('Cross Entropy Loss')\n",
    "plt.plot(hist.history['loss'], color='blue', label='train')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='test')\n",
    "# plot accuracy\n",
    "plt.subplot(3,1,3)\n",
    "plt.title('Classification Accuracy')\n",
    "plt.plot(hist.history['accuracy'], color='blue', label='train')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange', label='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('animal.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Test the model\n",
    "1. Import libraries\n",
    "2. Load the model\n",
    "3. Load the image\n",
    "4. Convert the image to CNN architecture\n",
    "5. Predict the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model (\"animal.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Load the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(\"bear.jpeg\", target_size=(64,64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Convert the image to CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.Image.Image"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type of image is still image\n",
    "type(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***We have to convert the image type to array***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **For CNN, the x_shape should be of 4 dimensions**, thus we must expand the x_shape from 3 to 4 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.expand_dims(x, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 64, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Predict the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.argmax(model.predict(x))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bears'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = ['bears', 'crows', 'elephants', 'racoons', 'rats']\n",
    "prediction = index[pred]\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'crows'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another Image\n",
    "img = image.load_img(\"crow.jpg\", target_size=(64,64))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "pred = np.argmax(model.predict(x))\n",
    "index[pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'elephants'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another Image\n",
    "img = image.load_img(\"elephant.jpeg\", target_size=(64,64))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "pred = np.argmax(model.predict(x))\n",
    "index[pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'racoons'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another Image\n",
    "img = image.load_img(\"racoon.jfif\", target_size=(64,64))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "pred = np.argmax(model.predict(x))\n",
    "index[pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rats'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another Image\n",
    "img = image.load_img(\"rat.jpg\", target_size=(64,64))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "pred = np.argmax(model.predict(x))\n",
    "index[pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
